{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386c2f3c",
   "metadata": {},
   "source": [
    "# Building an index\n",
    "\n",
    "In this notebook we demonstrate how one can create a Pyserini-backed BM25 index of a dataset avaiable on the Hugging Face Hub. We start by importing necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ef64fc-dbf4-41df-8f91-711923d34e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pyserini.index.lucene import LuceneIndexer, IndexReader\n",
    "from pyserini.pyclass import autoclass\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from datasets.utils.py_utils import convert_file_size_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c8dc8",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "We will work with the IMDB dataset of movie recommendations, available on the Hugging Face hub at https://huggingface.co/datasets/imdb. We begin by loading the dataset like below - this operation downloads the full dataset on disk and creates a local cache to be reused in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b597895-04cc-4667-a002-ad27d2363aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/piktus_huggingface_co/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = load_dataset(\"imdb\", split=\"train\")\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ed283",
   "metadata": {},
   "source": [
    "Pyserini expects a specific format of the documents which are being indexed - namely, a string `id` column contaninig a unique identigier of a given datapoint and a `contents` column containing the text of the document. We leverage Huggin Face `datasets` API to reformat the dataset. More on datasets can be found here  https://huggingface.co/docs/datasets/index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678d2478-abac-407f-81d2-b24ad5b78f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['contents', 'id'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = dset.add_column(\"id\", [str(i) for i in range(len(dset))])\n",
    "dset = dset.rename_column(\"text\", \"contents\")\n",
    "dset = dset.select_columns([\"id\", \"contents\"])\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e838c8",
   "metadata": {},
   "source": [
    "Let's see what a single document looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a1cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contents': 'I rented I AM CURIOUS-YELLOW from my video store because of all '\n",
      "             'the controversy that surrounded it when it was first released in '\n",
      "             '1967. I also heard that at first it was seized by U.S. customs '\n",
      "             'if it ever tried to enter this country, therefore being a fan of '\n",
      "             'films considered \"controversial\" I really had to see this for '\n",
      "             'myself.<br /><br />The plot is centered around a young Swedish '\n",
      "             'drama student named Lena who wants to learn everything she can '\n",
      "             'about life. In particular she wants to focus her attentions to '\n",
      "             'making some sort of documentary on what the average Swede '\n",
      "             'thought about certain political issues such as the Vietnam War '\n",
      "             'and race issues in the United States. In between asking '\n",
      "             'politicians and ordinary denizens of Stockholm about their '\n",
      "             'opinions on politics, she has sex with her drama teacher, '\n",
      "             'classmates, and married men.<br /><br />What kills me about I AM '\n",
      "             'CURIOUS-YELLOW is that 40 years ago, this was considered '\n",
      "             'pornographic. Really, the sex and nudity scenes are few and far '\n",
      "             \"between, even then it's not shot like some cheaply made porno. \"\n",
      "             'While my countrymen mind find it shocking, in reality sex and '\n",
      "             'nudity are a major staple in Swedish cinema. Even Ingmar '\n",
      "             'Bergman, arguably their answer to good old boy John Ford, had '\n",
      "             'sex scenes in his films.<br /><br />I do commend the filmmakers '\n",
      "             'for the fact that any sex shown in the film is shown for '\n",
      "             'artistic purposes rather than just to shock people and make '\n",
      "             'money to be shown in pornographic theaters in America. I AM '\n",
      "             'CURIOUS-YELLOW is a good film for anyone wanting to study the '\n",
      "             'meat and potatoes (no pun intended) of Swedish cinema. But '\n",
      "             \"really, this film doesn't have much of a plot.\",\n",
      " 'id': '0'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90118cf1",
   "metadata": {},
   "source": [
    "In order to speed up index building we shard the dataset into multiple files which can then be processed concurrently by Pyserini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9603c7-8099-4f4a-b225-7dcda76fd6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharding into 4 JSONL files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdce1a66dc846779bf451d3934f0a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4641dbdf554fb38e1d3fae18a64fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a027c080884e456c81bc0d6177e4a87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec60d572864433f8abb064a8b080fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9729fcb29ab340f08dfe6f738625d69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shard_dir = f\"../shards/imdb\"\n",
    "max_shard_size = convert_file_size_to_int(\"10MB\")\n",
    "dataset_nbytes = dset.data.nbytes\n",
    "num_shards = int(dataset_nbytes / max_shard_size) + 1\n",
    "num_shards = max(num_shards, 1)\n",
    "print(f\"Sharding into {num_shards} JSONL files.\")\n",
    "os.makedirs(shard_dir, exist_ok=True)\n",
    "for shard_index in tqdm(range(num_shards)):\n",
    "    shard = dset.shard(num_shards=num_shards, index=shard_index, contiguous=True)\n",
    "    shard.to_json(\n",
    "        f\"{shard_dir}/docs-{shard_index:03d}.jsonl\", orient=\"records\", lines=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585dac1",
   "metadata": {},
   "source": [
    "## Offline indexing\n",
    "The most straightforward option is to index a dataset downloaded locally. We already have the dataset in the `../shards/imdb/` folder. We leverage the Pyserini API to build the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab5c809-8eab-4f03-b67e-1fb181144249",
   "metadata": {},
   "outputs": [],
   "source": [
    "JIndexCollection = autoclass(\"io.anserini.index.IndexCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda07700-4ef0-434f-8575-4c138cddd6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexing_args = [\n",
    "    \"-input\",\n",
    "    shard_dir,\n",
    "    \"-index\",\n",
    "    \"../indexes/imdb\",\n",
    "    \"-collection\",\n",
    "    \"JsonCollection\",\n",
    "    \"-threads\",\n",
    "    \"28\",\n",
    "    \"-language\",\n",
    "    \"en\",\n",
    "    \"-storePositions\",\n",
    "    \"-storeDocvectors\",\n",
    "    \"-storeContents\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5eea38-473c-4cea-bb37-0156c386a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2023-05-17 12:34:45,495 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2023-05-17 12:34:45,497 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2023-05-17 12:34:45,497 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2023-05-17 12:34:45,497 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: ../shards/imdb\n",
      "2023-05-17 12:34:45,498 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2023-05-17 12:34:45,498 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2023-05-17 12:34:45,499 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 28\n",
      "2023-05-17 12:34:45,499 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2023-05-17 12:34:45,499 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2023-05-17 12:34:45,499 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2023-05-17 12:34:45,500 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2023-05-17 12:34:45,500 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? true\n",
      "2023-05-17 12:34:45,501 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? true\n",
      "2023-05-17 12:34:45,501 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? true\n",
      "2023-05-17 12:34:45,501 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? false\n",
      "2023-05-17 12:34:45,501 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
      "2023-05-17 12:34:45,502 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2023-05-17 12:34:45,502 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2023-05-17 12:34:45,502 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2023-05-17 12:34:45,503 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: ../indexes/imdb\n",
      "2023-05-17 12:34:45,505 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2023-05-17 12:34:45,516 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2023-05-17 12:34:45,517 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2023-05-17 12:34:45,517 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2023-05-17 12:34:45,518 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2023-05-17 12:34:45,673 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 28 threads initialized.\n",
      "2023-05-17 12:34:45,673 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in ../shards/imdb\n",
      "2023-05-17 12:34:45,676 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 4 files found\n",
      "2023-05-17 12:34:45,677 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2023-05-17 12:34:48,309 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - imdb/docs-001.jsonl: 6250 docs added.\n",
      "2023-05-17 12:34:48,340 DEBUG [pool-2-thread-2] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - imdb/docs-000.jsonl: 6250 docs added.\n",
      "2023-05-17 12:34:48,405 DEBUG [pool-2-thread-4] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - imdb/docs-003.jsonl: 6250 docs added.\n",
      "2023-05-17 12:34:48,419 DEBUG [pool-2-thread-3] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - imdb/docs-002.jsonl: 6250 docs added.\n",
      "2023-05-17 12:34:49,946 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 25,000 documents indexed\n",
      "2023-05-17 12:34:49,946 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2023-05-17 12:34:49,947 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:           25,000\n",
      "2023-05-17 12:34:49,947 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2023-05-17 12:34:49,947 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2023-05-17 12:34:49,947 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2023-05-17 12:34:49,947 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "CPU times: user 36.3 s, sys: 3.23 s, total: 39.5 s\n",
      "Wall time: 4.51 s\n",
      "2023-05-17 12:34:49,953 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 25,000 documents indexed in 00:00:04\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "JIndexCollection.main(indexing_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb7546",
   "metadata": {},
   "source": [
    "The index is now built and available for querying in the `../indexes/imdb` folder. Note that the same index can be built using command line interface by running:\n",
    "```\n",
    "python -m pyserini.index.lucene \\\n",
    "    --collection JsonCollection\n",
    "    --input ../shards/imdb/\n",
    "    --index ../indexes/imdb/\n",
    "    --threads 28\n",
    "    --storePositions\n",
    "    --storeDocvectors\n",
    "    --storeRaw\n",
    "    --language en\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0813d5",
   "metadata": {},
   "source": [
    "## Datasets streaming\n",
    "One of the contributions of our collaboration is adding the ability to stream data directly into the index, without the need to dump the corpus into a local directory first. This can be combined with the data streaming feature available on the Hugging Face hub - https://huggingface.co/docs/datasets/stream. This solution removes the need to save the full dataset on disk which is particularly useful in low-disk environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7981468-d6b7-474d-a95b-6820624b4f67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x7f61906bda80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_streaming = load_dataset(\"imdb\", split=\"train\", streaming=True)\n",
    "dset_streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92860d4e-0ed5-4e55-821c-69e2421a6665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:40:47,715 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:141) - Using DefaultEnglishAnalyzer\n",
      "2023-05-17 12:40:47,716 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:142) - Stemmer: porter\n",
      "2023-05-17 12:40:47,716 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:143) - Keep stopwords? false\n",
      "2023-05-17 12:40:47,716 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:144) - Stopwords file: null\n"
     ]
    }
   ],
   "source": [
    "streaming_indexer = LuceneIndexer(\"../indexes/imdb-streaming\", threads=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "000f26b1-1004-4eeb-b72c-7bb8f3e77ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c5f7d719044eaab574013982a22711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 229 ms, total: 16.1 s\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, row in tqdm(enumerate(dset_streaming)):\n",
    "    streaming_indexer.add_doc_dict({\"contents\": row[\"text\"], \"id\": str(i)})\n",
    "streaming_indexer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "102e0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:42:21,062 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:141) - Using DefaultEnglishAnalyzer\n",
      "2023-05-17 12:42:21,063 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:142) - Stemmer: porter\n",
      "2023-05-17 12:42:21,063 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:143) - Keep stopwords? false\n",
      "2023-05-17 12:42:21,063 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:144) - Stopwords file: null\n"
     ]
    }
   ],
   "source": [
    "dset_streaming = load_dataset(\"imdb\", split=\"train\", streaming=True)\n",
    "batched_streaming_indexer = LuceneIndexer(\n",
    "    \"../indexes/imdb-streaming-batched\", threads=28\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66299771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41733636ece4486a025ff5808288d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 864 ms, total: 18.3 s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 1000\n",
    "batch = []\n",
    "\n",
    "for i, row in tqdm(enumerate(dset_streaming)):\n",
    "    batch.append({\"contents\": row[\"text\"], \"id\": str(i)})\n",
    "    if len(batch) >= batch_size:\n",
    "        batched_streaming_indexer.add_batch_dict(batch)\n",
    "        batch = []\n",
    "\n",
    "if len(batch) >= batch_size:\n",
    "    batched_streaming_indexer.add_batch_dict(batch)\n",
    "\n",
    "batched_streaming_indexer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c7865",
   "metadata": {},
   "source": [
    "Streaming datasets from the Hugging Face Hub comes with an expected slowdown due to the need to maintain a network connection with the hub. To better see the speed difference between the non-batched vs the batched variant of streaming data into a Pyserini index we also experiment with streaming into an index using local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a923552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:36:36,806 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:141) - Using DefaultEnglishAnalyzer\n",
      "2023-05-17 12:36:36,807 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:142) - Stemmer: porter\n",
      "2023-05-17 12:36:36,807 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:143) - Keep stopwords? false\n",
      "2023-05-17 12:36:36,807 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:144) - Stopwords file: null\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b211c46c42e43d58ee922e52410b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.3 s, sys: 342 ms, total: 7.64 s\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "streaming_indexer = LuceneIndexer(\"../indexes/imdb-streaming\", threads=28)\n",
    "for i, row in tqdm(enumerate(dset)):\n",
    "    streaming_indexer.add_doc_dict(row)\n",
    "streaming_indexer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a398b7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-17 12:36:43,293 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:141) - Using DefaultEnglishAnalyzer\n",
      "2023-05-17 12:36:43,294 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:142) - Stemmer: porter\n",
      "2023-05-17 12:36:43,294 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:143) - Keep stopwords? false\n",
      "2023-05-17 12:36:43,294 INFO  [main] index.SimpleIndexer (SimpleIndexer.java:144) - Stopwords file: null\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a43079c4174c1fb0a93556013aae9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 982 ms, total: 13.1 s\n",
      "Wall time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batched_streaming_indexer = LuceneIndexer(\n",
    "    \"../indexes/imdb-streaming-batched\", threads=28\n",
    ")\n",
    "batch_size = 1000\n",
    "batch = []\n",
    "\n",
    "for i, row in tqdm(enumerate(dset)):\n",
    "    batch.append(row)\n",
    "    if len(batch) >= batch_size:\n",
    "        batched_streaming_indexer.add_batch_dict(batch)\n",
    "        batch = []\n",
    "\n",
    "if len(batch) >= batch_size:\n",
    "    batched_streaming_indexer.add_batch_dict(batch)\n",
    "\n",
    "batched_streaming_indexer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9c7b9",
   "metadata": {},
   "source": [
    "As we can see, batched streaming is almost twice as fast for the considered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776abcd",
   "metadata": {},
   "source": [
    "# Using the index\n",
    "Follow the next tutorial to see how you can interact with your index:\n",
    "- searching: https://github.com/huggingface/gaia/blob/main/notebooks/02-searching.ipynb\n",
    "- analysis: https://github.com/huggingface/gaia/blob/main/notebooks/03-analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461cd7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
